{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #007BFF; height: 4px; width: 100%;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Effortful Retrieval Experiments**\n",
    "\n",
    "We will conduct a series of experiments to evaluate memory retrieval performance in CNNs under different conditions of retrieval difficulty. To vary retrieval difficulty, each experiment manipulates a key difficulty variable, interstimulus interval (ISI), criterion level, noise level, and occlusion. To evaluate model performance, each experiment computes classification accuracy, retrieval strength (precision, recall, F1-score), and forgetting rate (change in accuracy over time for previously learned items). We will be using a standard pre-trained `ResNet-18` CNN and fine-tune using the CIFAR-10 image dataset (publicly available via `torchvision.datasets`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Table of Contents**\n",
    "\n",
    "1. Notebook Setup\n",
    "2. Dataset Preparation\n",
    "3. Experiment Setup\n",
    "    a. Defining the CNN model\n",
    "    b. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #007BFF; height: 4px; width: 100%;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Notebook Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #007BFF; height: 4px; width: 100%;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Dataset Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for different difficulty manipulations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform_train, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform_test, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #007BFF; height: 4px; width: 100%;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Experiment Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Defining the CNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_cnn():\n",
    "    # Pretrained ResNet-18\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    return model, criterion, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Abstracted training function for all experiments**\n",
    "\n",
    "Can vary the following:\n",
    "- Retrieval condition (massed or spaced)\n",
    "- Dataset noise level\n",
    "- Occlusion percetage\n",
    "\n",
    "Returns accuracy and loss across epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, epochs=10, retrieval_condition=\"massed\", noise_level=0, occlusion_percent=0):\n",
    "    model.train()\n",
    "    history = {\"accuracy\": [], \"loss\": []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        correct, total, running_loss = 0, 0, 0.0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # spaced retrieval\n",
    "            if retrieval_condition == \"spaced\":\n",
    "                if random.random() < 0.5:\n",
    "                    continue\n",
    "\n",
    "            # dataset noise level\n",
    "            if noise_level > 0:\n",
    "                noise = torch.randn_like(images) * noise_level\n",
    "                images = images + noise\n",
    "                images = torch.clamp(images, 0, 1)\n",
    "\n",
    "            # occlusion percentage\n",
    "            if occlusion_percent > 0:\n",
    "                mask_size = int(32 * occlusion_percent)\n",
    "                x_start = random.randint(0, 32 - mask_size)\n",
    "                y_start = random.randint(0, 32 - mask_size)\n",
    "                images[:, :, x_start:x_start+mask_size, y_start:y_start+mask_size] = 0\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        acc = 100. * correct / total\n",
    "        history[\"accuracy\"].append(acc)\n",
    "        history[\"loss\"].append(running_loss / len(train_loader))\n",
    "        print(f\"Epoch {epoch+1}: Loss: {running_loss:.4f}, Accuracy: {acc:.2f}%\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Evaluating model performance functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
    "    recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_forgetting_rate(model, test_loader, delay=10):\n",
    "    initial_acc, _, _, _ = evaluate_model(model, test_loader)\n",
    "    print(f\"Initial Accuracy: {initial_acc:.2f}%\")\n",
    "\n",
    "    # simulate \"forgetting\" by adding a delay before retesting\n",
    "    print(f\"Waiting {delay} minutes before retesting...\")\n",
    "    time.sleep(delay * 60)\n",
    "\n",
    "    final_acc, _, _, _ = evaluate_model(model, test_loader)\n",
    "    forgetting_rate = (initial_acc - final_acc) / initial_acc * 100\n",
    "    print(f\"Forgetting Rate: {forgetting_rate:.2f}%\")\n",
    "\n",
    "    return forgetting_rate\n",
    "\n",
    "print(\"\\nMeasuring Forgetting Rate for Spaced Learning...\")\n",
    "forgetting_spaced = measure_forgetting_rate(model, test_loader, delay=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #007BFF; height: 4px; width: 100%;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Experimental Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Experiment 1: Spaced vs. Massed Learning (ISI)**\n",
    "\n",
    "**Objective**: Test whether spaced learning (inserting delays between learning and retrieval) enhances memory retention in CNNs compared to massed learning (immediate retrieval).\n",
    "\n",
    "**Training Protocol**\n",
    "\n",
    "1. Massed Learning: Train CNN on a batch of images and immediately test on the same batch.\n",
    "2. Spaced Learning: Train CNN on multiple image sets (thus introduce delay) before testing each set in order.\n",
    "\n",
    "**Benchmark(s)**\n",
    "\n",
    "1. Compare against standard CNN training accuracy.\n",
    "2. Measure memory degradation over multiple test intervals.\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "- Spaced retrieval outperforms massed retrieval over time → supports effortful retrieval hypothesis.\n",
    "- There is no significant difference → spaced learning may not benefit CNNs as it does in human learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train under massed retrieval condition (easy)\n",
    "print(\"Training with Massed Learning...\")\n",
    "history_massed = train_model(model, train_loader, criterion, optimizer, epochs=10, retrieval_condition=\"massed\")\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nEvaluating Massed Learning Model...\")\n",
    "evaluate_model(model, test_loader)\n",
    "\n",
    "# Train under spaced retrieval condition (harder)\n",
    "print(\"\\nTraining with Spaced Learning...\")\n",
    "history_spaced = train_model(model, train_loader, criterion, optimizer, epochs=10, retrieval_condition=\"spaced\")\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nEvaluating Spaced Learning Model...\")\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Experiment 2: Criterion Level (Number of Retrievals Before Dropping)**\n",
    "\n",
    "**Objective**: Examine whether requiring multiple successful retrievals before dropping an item from training strengthens CNN memory retention.\n",
    "\n",
    "**Training Protocol**\n",
    "1. Image must be classified correctly 1 time before dropping.\n",
    "2. Image must be classified correctly 3 times before dropping.\n",
    "3. Image must be classified correctly 5 times before dropping.\n",
    "\n",
    "**Benchmark(s)**: Compare against standard single-pass training\n",
    "\n",
    "**Interpretation**\n",
    "- Higher retrieval criteria improve retention → CNNs exhibit similar memory effects as humans.\n",
    "- No significant improvement → retrieval-based learning might not transfer well to CNNs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Experiment 3: Noise Levels in Images**\n",
    "\n",
    "**Objective**: Investigate how introducing noise into images affects retrieval difficulty and model retention over time.\n",
    "\n",
    "**Training Protocol**\n",
    "1. Train CNN on clean images\n",
    "2. Test under different noise conditions:\n",
    "    a. Low noise (Gaussian noise, σ=0.1)\n",
    "    b. Medium noise (σ=0.3)\n",
    "    c. High noise (σ=0.5)\n",
    "\n",
    "*Note*: To test under different noise conditions, we will modify the image dataset using `torchvision.transforms`. σ parameters are subject to change.\n",
    "\n",
    "**Benchmark(s)**\n",
    "1. Compare against standard CNN performance on clean images.\n",
    "2. Track degradation trends as noise increases.\n",
    "\n",
    "**Interpretation**\n",
    "- Retrieval performance drops significantly with noise →  retrieval difficulty negatively affects CNN retention.\n",
    "- Model adapts well to noise → CNNs may be robust to effortful retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Experiment 4: Occluding Parts of Images**\n",
    "\n",
    "**Objective**: Test whether CNNs can learn to retrieve images even when parts of the input are missing, mimicking retrieval with incomplete cues in human memory.\n",
    "\n",
    "**Training Protocol**\n",
    "1. Train on full images\n",
    "2. Test under occlusion conditions:\n",
    "    a. 25% occlusion (randomly block part of the image)\n",
    "    b. 50% occlusion\n",
    "    c. 75% occlusion\n",
    "\n",
    "**Benchmark(s)**: Compare against standard CNN performance on full images.\n",
    "\n",
    "**Interpretation**\n",
    "- CNNs struggle with occlusion → retrieval difficulty negatively affects performance.\n",
    "- CNNs maintain accuracy → effortful retrieval mechanisms might apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #007BFF; height: 4px; width: 100%;\"></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs109a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
